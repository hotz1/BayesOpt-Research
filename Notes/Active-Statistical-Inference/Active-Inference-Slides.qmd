---
title: 
  "Active Statistical Inference"
subtitle:
  "By Tijana Zrnic & Emmanuel J. CandÃ¨s"
format: 
  beamer:
    navigation: empty
pdf-engine: pdflatex
include-in-header: 
  text: |
    \usepackage{graphicx, amssymb, amsmath, amsthm, amsfonts, mathrsfs}
    \setbeamertemplate{itemize subitem}[ball]
    \setbeamertemplate{itemize subsubitem}[square]
    \usefonttheme[onlymath]{serif}
    \input{../tex-macros/math-alphabets.tex}
    \input{../tex-macros/math-macros.tex}
---

## Problem Setting 

- We have a collection of $n$ values $X_1, X_2, \dots, X_n \simiid \bbP_{X}$. Each $X_{i}$ has a corresponding *label* $Y_{i}$ which is unobserved, with $Y_{i} \sim \bbP_{Y\mid{X}}$.
- We want to perform inference on some parameter $\theta^{\star}$ (e.g. the mean label $\expec{Y_{i}}$) which is a functional of $\bbP_{(X,Y)} := \bbP_{X} \times \bbP_{Y\mid{X}}$.
  * $\theta^{\star}$ is an element of some parameter space $\Theta$.
  * In particular, the authors focus on hypothesis tests and/or constructing confidence intervals for the parameter $\theta^{\star}$. 
- We have a budget of $n_{b} \ll n$ labels which we can collect.
  * The goal is to have the *expected number* of collected labels ($n_{\text{lab}}$) be less than $n_{b}$
- We have some (often black-box) model $f$ for predicting $Y_{i}$ given $X_{i}$.

## Loss Function

- To perform inference on the parameter $\theta^{\star}$, we utilize a loss function $\ell_{\theta}(X, Y)$ which is **convex** w.r.t $\theta$. 
- Possible examples of this loss are:
  * $\ell_{\theta}(x,y) = \frac{1}{2}(y - \theta)^{2}$, target is $\theta^{\star} = \expec{Y}$\vspace{1em}
  * $\ell_{\theta}(x,y) = \frac{1}{2}(y - x^{\top}\theta)^{2}$, target is linear regression coefficients \vspace{1em}
  * $\ell_{\theta}(x,y) = (1 - q)(\theta - y)\mathbf{1}\{y \le \theta\} + q(y-\theta)\mathbf{1}\{y > \theta\}$, target is $q^{\text{th}}$ quantile of $Y$ for $0 < q < 1$\vspace{1em}
- For Bayesian Optimization, we want to find $x^{\star}$ which maximizes $g(x^{\star})$ for the unknown function $g$. In a scenario with zero observational noise, this is effectively the $1.00^{\text{th}}$ quantile of $Y$.

## Batch and Sequential Settings

- The authors propose two versions of their algorithm; the *batch* and *sequential* setting.
- In the *batch* setting, we have a pre-existing predictive model $f$ and simultaneously decide whether or not to acquire $Y_{i}$.
  * This version is conceptually easier but reliant on a good model $f$.
- In the *sequential* setting, we instead acquire $Y_{i}$ one point at a time and update the predictive model $f$ in accordance with the new data.
  * This is more in line with Bayesian optimization, but from a more frequentist angle.
  * The *sequential* setting also allows us to train a model $f$ ``from scratch", which is similar to starting with an uninformative prior for $Y_{i} \mid X_{i}$ and doing posterior updates.
  
## Sequential Sampling

- To choose the next label to collect in the *sequential* setting, the authors create a sampling rule $\pi: \calX \to [0,1]$ and collect the label $Y_{i}$ with probability $\pi(X_{i})$.
  * The value of $\pi(X_{i})$ is based on the uncertainty of $f(X_{i})$, with $\pi(X_{i}) \approx 1$ when $f(X_{i})$ is uncertain and $\pi(X_{i}) \approx 0$ when $f(X_{i})$ has high certainty. 
  * The uncertainty is measured as a function $u(\cdot)$, where $\pi(\cdot) \propto u(\cdot)$ is scaled to ensure $\expec{n_{\text{lab}}} \le n_{b}$.
- At each step $t \in \{1, 2, \dots, n\}$, we observe $X_{t} \in \calX$ and collect the label $Y_{t}$ with probability $\pi_{t}(X_{t})$.
  * $\pi_{t}(\cdot)$ is a **scaled** measure of the uncertainty of $f$ after collecting the labelled dataset $\{(X_{i}, Y_{i})\}_{i=1}^{n}$.
  
## Sequential Sampling (cont.)

- For general convex $M$-estimation problems, the sequential estimator is $$\hat{\theta}^{\pi_{n}} = \arg\min_{\theta \in \Theta}L^{\pi_{n}}(\theta)$$
- In the equation above, we define $$L^{\pi_{n}}(\theta) = \frac{1}{n}\sum_{t=1}^{n}\left[\ell_{\theta,t}^{f_{t}}+ (\ell_{\theta,t} - \ell_{\theta,t}^{f_{t}})\frac{\xi_{t}}{\pi_{t}(X_{t})}\right]$$
- Under the **Lindeberg condition**, we find that $\hat{\theta}^{\pi_{n}}$ is asymptotically Normal, and this can be used to construct $1-\alpha$ confidence intervals for $\theta^{\star}$. 

## Similarities to `BayesOpt`

- The *batch* setting is fairly reliant on the existence of a pre-trained model $f$, but the *sequential* setting has several similarities to `BayesOpt`.
- The overall methodology of the *sequential* setting is quite similar to Bayesian Optimization as the method involves sequential data collection and updating our ``beliefs" (the function $f_{t}$) in accordance with new data.
- The uncertainty function $u(\cdot)$ **acts** similarly to a utility function used for guiding data collection.
  * The primary difference is that $u(\cdot)$ is mostly reliant on uncertainty regarding the predicted value of $Y_{i} \mid X_{i}$ instead of depending on the loss function and/or the target $\theta^{\star}$.

## Differences from `BayesOpt`

- The proposed active inference method is suited for $M$-estimation problems, and Bayesian optimization does not (really) fall under this category.
- The active inference method involves an initial sample of points $X_1, X_2, \dots, X_{n} \simiid \bbP_{X}$ where we can choose to acquire the corresponding labels, as opposed to `BayesOpt`, which does not need to fix the data points *a priori*.
- The *sequential* setting seems particularly useful when the features of $X$ are categorical/discrete because `BayesOpt` requires a compact space $\calX$.