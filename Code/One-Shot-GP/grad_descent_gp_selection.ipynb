{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90ef60b-b4ba-4b8c-a733-f9037bcdc5bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Gradient Descent GP Selection\n",
    "\n",
    "A Python notebook regarding Gaussian Processes based primarily on two pre-prints: *Computation-Aware Gaussian Processes* and *Approximation-Aware Bayesian Optimization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b841ece8-88a7-4066-9ab6-6f2b657ee492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2353f7e3030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import jaxtyping\n",
    "except ImportError:\n",
    "    %pip install jaxtyping\n",
    "\n",
    "from typing import Optional\n",
    "# Type hints are strictly optional, but personally I find that they make code more reasonable\n",
    "\n",
    "from jaxtyping import Float, Integer\n",
    "# This package allows type annotations that include the size of torch Tensors/numpy arrays\n",
    "# It's not necessary, but it helps with understanding what each function does\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set DTYPE and DEVICE variables for torch tensors\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Set a seed (for reproducibility)\n",
    "torch.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9ad90-4239-4343-b402-3c38626de059",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Initially, we have some existing dataset $\\mathcal{D}_{0} = \\{(x_{i}, y_{i})\\}_{i=1}^{n}$, with $x_{i} \\in \\mathbb{R}^{d}, y_{i} \\in \\mathbb{R}$. Equivalently, we let $\\mathcal{D}_{0} = (\\mathbf{X}, \\mathbf{y})$, with $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}, \\mathbf{y} \\in \\mathbb{R}^{n}$. \n",
    "\n",
    "We want to use Gaussian Process regression to perform Bayesian optimization to find $x^{*} = \\arg\\max_{\\mathbb{R}^{d}}f(\\cdot)$, for the unknown objective function $f(\\cdot): \\mathbb{R}^{d} \\to \\mathbb{R}$.\n",
    "\n",
    "Unfortunately, the standard `BayesOpt` formulation has $\\mathcal{O}(n^3)$ time complexity, as the \"proper\" mathematical formulation requires a matrix inversion. To reduce the computational complexity, we include an \"action matrix\" $\\mathbf{S} \\in \\mathbb{R}^{n \\times k}$ for $k \\ll n$, which yields $\\mathcal{O}(n^2{k})$ time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d475b-d952-411e-a3bc-7dfc6f56ed5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mu(X: Float[Tensor, \"N D\"]) -> Float[Tensor, \"N\"]:\n",
    "    r\"\"\"\n",
    "    Computes the (very lame) zero mean function mu(X) = 0\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.zeros(*X.shape[:-1], dtype=X.dtype, device=X.device)\n",
    "\n",
    "    # This return statement might seem like it's a pedantic way just to return the number 0 :)\n",
    "    # It's not:\n",
    "    # - if we want to compute a batch of GPs, the batch size of the returned zero\n",
    "    #   tensor will match the batch size of X\n",
    "    # - if X is a float64 tensor rather than float32, the returned zero tensor will match the correct dtype\n",
    "    # - if X is on the GPU rather than the CPU, the returned zero tensor will also be on the same device\n",
    "\n",
    "    # You don't always have to be this pedantic, but it's not a bad habit to get into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "242a8796-3a1f-4828-a69c-03eb7042862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "def hartmann_six(X: Float[Tensor, \"N 6\"]) -> Float[Tensor, \"N\"]:\n",
    "    r\"\"\"\n",
    "    Computes the value of the Hartmann six-dimensional test function on N rows of input data\n",
    "    More info on this test function at: https://www.sfu.ca/~ssurjano/hart6.html\n",
    "    \"\"\"\n",
    "    alpha = torch.tensor([1.0, 1.2, 3.0, 3.2], dtype = DTYPE, device = X.device)\n",
    "    A = torch.tensor([[10, 3, 17, 3.5, 1.7, 8],\n",
    "                      [0.05, 10, 17, 0.1, 8, 14],\n",
    "                      [3, 3.5, 1.7, 10, 17, 8],\n",
    "                      [17, 8, 0.05, 10, 0.1, 14]],\n",
    "                     dtype = DTYPE, device = X.device)\n",
    "    P = 1e-4 * torch.tensor([[1312, 1696, 5569, 124, 8283, 5886],\n",
    "                             [2329, 4135, 8307, 3736, 1004, 9991],\n",
    "                             [2348, 1451, 3522, 2883, 3047, 6650],\n",
    "                             [4047, 8828, 8732, 5743, 1091, 381]], \n",
    "                            dtype = DTYPE, device = X.device)\n",
    "\n",
    "    # Calculate \"inner sums\" \n",
    "    inner_sums: Float[Tensor, \"N 4\"] = torch.sum(A * (X.unsqueeze(-2) - P).pow(2), -1)\n",
    "\n",
    "    # Exponentiate and compute \"outer sums\"\n",
    "    outer_sums: Float[Tensor, \"N\"] = -alpha @ torch.exp(-inner_sums).mT\n",
    "    \n",
    "    return(outer_sums)\n",
    "\n",
    "# Just checking the function works as desired\n",
    "test_vecs = torch.tensor([[0., 0., 0., 0., 0., 0.],\n",
    "                          [0.20169, 0.150011, 0.476874, 0.275332, 0.311652, 0.657300]])\n",
    "print(hartmann_six(test_vecs).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "036d9446-64ea-439e-bdfd-0db356910339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r\"\"\"\n",
    "# alpha <- c(1.0, 1.2, 3.0, 3.2)\n",
    "#   A <- c(10, 3, 17, 3.5, 1.7, 8,\n",
    "#          0.05, 10, 17, 0.1, 8, 14,\n",
    "#          3, 3.5, 1.7, 10, 17, 8,\n",
    "#          17, 8, 0.05, 10, 0.1, 14)\n",
    "#   A <- matrix(A, 4, 6, byrow=TRUE)\n",
    "#   P <- 10^(-4) * c(1312, 1696, 5569, 124, 8283, 5886,\n",
    "#                    2329, 4135, 8307, 3736, 1004, 9991,\n",
    "#                    2348, 1451, 3522, 2883, 3047, 6650,\n",
    "#                    4047, 8828, 8732, 5743, 1091, 381)\n",
    "#   P <- matrix(P, 4, 6, byrow=TRUE)\n",
    "# \"\"\"\n",
    "# P: Float[Tensor, \"4 6\"] = 1e-4 * torch.tensor([[1312, 1696, 5569, 124, 8283, 5886],\n",
    "#                                                    [2329, 4135, 8307, 3736, 1004, 9991],\n",
    "#                                                    [2348, 1451, 3522, 2883, 3047, 6650],\n",
    "#                                                    [4047, 8828, 8732, 5743, 1091, 381]])\n",
    "\n",
    "# test1 = 1e-2 * torch.tensor([[1, 2, 3, 4, 5, 6], [1, 2, 4, 8, 16, 32], [20.169, 15.0011, 47.6874, 27.5332, 31.1652, 65.7300]])\n",
    "# test2 = (torch.unsqueeze(test1, -2)).pow(2)\n",
    "# test2.sum(-1)\n",
    "# hartmann_six(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc899a50-b8e3-474c-bb86-9d8549035d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
